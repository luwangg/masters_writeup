\chapter{Literature Review}

As discussed by (Electronic warfare and radar systems engineering handbook), in Electronic Warfare, AoA is the most critical parameter in hostile emitter sorting as it cannot be varied from pulse to pulse by the emitter. This may not directly translate to RFI hunting as emitters are not intentionally being hostile, but the RFI sources are still constrained in that their AoA parameter cannot be altered and hence is useful. 

\section{Stuff from Schleher}
The simplest way to do DF is scan a narrow beam antenna. The position of the antenna which produces the highest output is the AoA. The antenna can be scanned physically by rotating it or electronically by a phased array. 
The down side of this approach is it cannot DF transients as it has a low POI. Well, POI as well as it needs time to scan around to figure out where the highest amplitude signal is.

Angular accuracy is:
\begin{equation}
  \Delta \theta = k \theta_B / \sqrt{SNR}
\end{equation}

Interferometer systems which use phase comparison for DF have a comparatively higher angular accuracy and rapid response which is good for transient detection. However, they impose stringent requirements on the phase matching for the RF chain which requires careful design, measurement and calibration. 

Selection of antenna spacing necessitates a trade off between angular accuracy and ambiguity. The further the elements are placed apart, the greater the accuracy, but the more ambiguity is introduced. It is well known that for a 2-element array, the lowest ambiguity which can be achieved is \SI{180}{\degree} which is when the elements are spaced half a wavelength apart. 
Of course, this \(\lambda/2\) is only valid for a single frequency. As soon as a different frequency needs to be received, the antennas will appear closer together or further apart, depending on whether the new frequency is higher or lower. As such, the specing is generally set by the highest frequency needed to be received, which puts an upper bound on the amount of ambiguity in the system. 

For a linear array, the array is often constructed with a long baseline (in the order of \(16\lambda\)) to provide high angular accuracy, and a short baseline \(\lambda/2\) to resolve the ambiguity introduced by the system. It must be noted that with a linear array, there is always an unresolvable \SI{180}{\degree} ambiguity, no matter how many elements are present.

DF can also be done via Doppler shift which involves rapidly switching which antenna is sampled in an array to simulate rapidly rotating the antenna. When the antenna is being switched toward the signal source, the received frequency will go up. When the sampled antenna is being switched away from the source, the frequency will go down. By seeing at which stage of the switching the frequency is increasing and at which stage it is decreasing, it can be determined where the source is.

TODO: insert summary table from page 384 here.

Geolocation is done by measuring AoA from multiple locations and then triangulating to ascertain the true location of the source. This is outside the scope of this project. This project seeks only to design an AoA system. Not a geolocation system. 

Probability of Intercept (POI) is a measure of the probability that the parameters of the EW receiving system match those of the target signal source at an instant in time. The key parameters are frequency and orientation. Frequency refers to whether the receiver is receiving on the frequency which is being transmitted. Orientation refers to whether the antennas of the receiver are pointed towards the signal source. 
For a \SI{100}{\percent} POI, the receiver needs to be wide open (as opposed to narrow-band scanning) and have omni directional antenna coverage. This \SI{100}{\percent} POI is essential to be able to intercept transient or impulsive signals.

\section{Introduction}
The purpose of this chapter is to provide a discussion into current strategies and implementations of direction finding systems. An analysis of the advantages and disadvantages of the various systems will take place which will aid in the later descision of which strategy to adopt for this project

\section{Signals}
As discussed by \cite{krim1996two}:

We are interested in extracting the parameters of a signal. This is what sensor array signal processing does.

We model the E-field of a narrow-band signal by:
\begin{equation}
  E(\vec{r}, t) = s(t) \exp \left\{ j(\omega t - \vec{r}\, \TRANSPOSE \vec{k}) \right\}
\end{equation}

Where:
\begin{itemize}
  \item \(s(t)\) is the slow (compared to the carrier) modulating signal with bandwidth \(B\)
  \item \(\omega\) is the carrier frequency
  \item \( \vec{r} \) is the radius vector, of form \( \begin{bmatrix} x, y, z, \end{bmatrix} \).
  \item \(\vec{k} = \alpha\omega\) which is the wave-vector where \(\alpha = \frac{1}{c}\) pointing in the direction of propagation. Note that the magnitude of the wave-vector is known as the wave-number: \(\lvert \vec{k} \rvert = k = \frac{\omega}{c} = \frac{2\pi}{\lambda}\). This implies: \(\vec{k} = k(\cos\theta \sin\theta)\TRANSPOSE\) where \(\theta\) is the angle of the incident wave.
\end{itemize}

If we have a receiver with a radius vector \(\vec{r_r} = \begin{bmatrix} x_r, y_r \end{bmatrix}\TRANSPOSE\)

Note that as per the narrowband assumption is is assumed that the array aperture be much less than the inverse relative bandwidth \((f/B)\)

It is shown that the output of an \(L\)-element array a \(L\)-dimensional vector of the steering vector scalar multiplied by the incident signal, given by
\begin{equation}
  \vec{x}(t) = \vec{a}(\theta).s(t)
\end{equation}

Here, \(\vec{a}(\theta) = \begin{bmatrix} a_1(\theta), a_2(\theta), ... , a_L(\theta) \end{bmatrix}\TRANSPOSE\) which is the steering vector.

  Furthermore, it is shown that the principle of superposition applies. If there are \(M\) incident signals they are simply summed together:
\begin{equation}
  \vec{x}(t) = \sum_{m=1}^{M} \vec{a}(\theta_m)\vec{s_m}(t)
\end{equation}

This can be re-written in a more compact form (now adding noise to the model):
\begin{equation}
  \vec{x}(t) = \mathbf{A}(\vec{\theta})\vec{s}(t) + \vec{n}(t)
\end{equation}

Where:
\begin{itemize} 
  \item we have re-written \(\sum_{m=1}^{M}\vec{a}(\theta_m)\) as a matrix of steering vectors
\begin{equation} 
  \mathbf{A}(\vec{\theta}) = \begin{bmatrix} \vec{a}(\theta_1), \vec{a}(\theta_2), ..., \vec{a}(\theta_M) \end{bmatrix} \\
\end{equation}
  \item we have re-written  \(\sum_{m=1}^{M}s_m(t)\) as a vector:
\begin{equation}
  \vec{s}(t) = \begin{bmatrix} s_t(t) \\ .. \\ s_M(t) \end{bmatrix}
\end{equation}
\end{itemize}
\section{Overview of Direction Finding}

\subsection{Model}
The model which will be discussed here is that presented in \cite{poisel2012electronic}.  

Let there be $N$ individual signal sources, where $\vec{s}(t)$ represents the resultant signal, being
\begin{equation}
\vec{s}(t) = \begin{bmatrix} s_{1}(t) & s_{2}(t) & s_3(t) & ... & s_N(t) \end{bmatrix}
\end{equation}

Now let there be an array of $M$ antenna elements receiving the signals, where the position of of the \(i\)th element is \(\vec{x}_{i} = \begin{bmatrix}x_i & y_i & z_i \end{bmatrix}\TRANSPOSE\). 
The signal received by this \(i\)th element is influenced by the element position. 
This can be represented as \(\vec{s}_i(t, \vec{x}_i)\), showing that the signal at an element is a function of the position of the element.
As discussed by \cite{krim1996two}, as this model contains both spacial and temporal information, it is sufficient to be able to attain spacial information about the signal. 

It is shown that the delay time for a signal arriving at the \(m\)th element is
\begin{equation}
  \tau_m(\vec{\theta}) 
 = \tau_m( \begin{bmatrix} \phi \\ \theta \end{bmatrix} )
  = \frac{1}{c} [ x_m\cos(\phi)\cos(\theta) + y_m\sin(\phi)\cos(\theta) + z_m\sin(\theta) ]
\end{equation}

Where \(\phi\) is the azimuth angle of the source and \(\theta\) is the elevation angle.
For a 2D space we let \(\theta = 0\) and hence simplify to:
\begin{equation}
 \tau_m(\phi) = \frac{1}{c} [ x_m\cos(\phi) + y_m\sin(\phi) ]
\end{equation}

The \(M \times 1\) steering matrix is
\begin{equation}
  \vec{a}_k(\vec{\theta}_k) = 
  \begin{bmatrix}
    e^{-j\omega_c \tau_1(\phi_k)} \\
    e^{-j\omega_c \tau_2(\phi_k)} \\
    ... \\
    e^{-j\omega_c \tau_M(\phi_k)} \\
  \end{bmatrix}
\end{equation}

\section{Antenna Array Fundamentals}
Here should be a discussion about how why arrays are necessary for DF. Then a discussion about some of the characteristics of an array.
\subsection{Array Manifold}
As discussed by \cite{sleiman2000antenna} \cite{karimi1996manifold} \cite{dacos1995estimating}. 

The antenna array manifold is said to be useful for direction finding systems, as signal subspace techniques such as MuSIC rely on searching for the best \(\vec{a}(p)\) for the detected signal \cite{karimi1996manifold}. 

It is shown by \cite{dacos1995estimating} that the output of an array of N sensors receiving M signals in the presence of noise is
\begin{equation}
\vec{x}(t) = \mtx{A}(\vec{p})\vec{m}(t) + \vec{n}(t)
\end{equation}
Where \(\vec{x}(t)\) is the N-dimensional output of the array, \(\vec{m}(t)\) is the M-dimensional set of signals received by the array, and \(\mtx{A}(\vec{p})\) is a \(N \times M\) matrix of source position vectors (SPV). 
A given SPV, \(\vec{a}(p_i)\), shows how the array responds to a source at location \(p_i\), where \(p_i\) is often an azimuth and elevation pair: \(p_i = (\theta_i, \phi_i)\).

For the case of a terrestrial-only system (which this project will be concerned with), \(\phi\) can be set to 0, meaning that \(p_i = \theta_i\), the azimuth angle of source \(i\), typically in the range \([0, 2\pi]\). Here, a SPV can be simplified to \(\vec{a}(\theta_i)\).

It is shown that if the \(N\) antennas are positioned symmetrically, the antenna array manifold is reduced from complex space \(\mathbf{C}^N\) to real space \(\mathbf{R}^N\) \cite{dacos1995estimating}.

The response of the array to a source from a certain location, \((\theta, \phi)\) is:
\begin{equation}
\vec{a}(\theta, \phi) = \vec{g}(\theta, \phi) \odot \exp \left\{ -j \mathbf{X}\TRANSPOSE \vec{k}(\theta,\phi) \right\}
\end{equation}
\cite{dacos1995estimating}.

Where:
\begin{itemize}
  \item \(\vec{g}(\theta, \phi)\) is a \(N\)-dimensional vector of complex number being the gain and phase response  of each element in the direction \((\theta, \phi)\). 
\item \(\mathbf{X}\TRANSPOSE\) is a \((N \times 3)\) matrix containing the \(x\), \(y\) and \(z\) coordinates of each of the N elements of the form \(\begin{bmatrix} \vec{x}, \vec{y}, \vec{z} \end{bmatrix}\TRANSPOSE\)
\item \(\vec{k}(\theta, \phi)\) is the wavenumber vector given by \(\vec{k}(\theta, \phi) = \pi \begin{bmatrix} \cos\theta\cos\phi, \sin\theta\cos\phi, \sin\phi \end{bmatrix}\TRANSPOSE \). Graphically, this equates to the 
\end{itemize}

For the purposes of this research the elements will all be located at the same elevation as we only with to locate terrestrial signals. Hence, this may be simplified to:
\begin{equation}
  \vec{a}(\theta) = \vec{g}(\theta) \odot \exp \left\{ -j \mathbf{X}\TRANSPOSE \vec{k}(\theta) \right\}
\end{equation}
    
Here, \(\mathbf{X}\TRANSPOSE\) is now a \((N \times 2)\) matrix of the form \(\begin{bmatrix} \vec{x}, \vec{y} \end{bmatrix}\) and \(\vec{k}(\theta) = \pi[\cos(\theta), \sin(\theta)]\TRANSPOSE\).

Furthermore, the \(\vec{g}\) term may be excluded if we assume omnidirectional elements. Although it is rare to deal with true omnidirectional antennas, for an antenna which is required to receive signals only in the azimuth plane, omnidirectional antennas such as dipoles might very well be used in practice. This hence simplifies to:

\begin{equation}
  \vec{a}(\theta) = \exp \left\{ -j \mathbf{X}\TRANSPOSE \vec{k}(\theta) \right\}
\end{equation}

Or, more expressively:
\begin{equation}
\vec{a}(\theta) = \exp \left\{ -j \begin{bmatrix} x_1, y_1 \\ x_2, y_2 \\ .., .. \\ x_N, y_N \end{bmatrix} \begin{bmatrix} \cos(\theta) \\ \sin(\theta) \end{bmatrix} \right\}
= \exp \left\{ -j \begin{bmatrix} x_1\cos(\theta) + y_1\sin(\theta) \\ x_2\cos(\theta) + y_2\sin(\theta)) \\ .., .. \\ x_N\cos(\theta) + y_N\sin(\theta) \end{bmatrix} \right\}
\end{equation}

Clearly, this is simply a vector of phase shifts introduced by each element in the array as a function of both the location of the element and the angle of the incident wave relative to some defined zero location and zero direction. It is said by \cite{dacos1995estimating} that this array manifold completely characterises the array. That paper goes into additional details on how the manifold may simplified for linear arrays, as well as the special properties which a manifold of a linear array possesses. This will not be discussed here as the array used for this DF system is not likely to be linear. 

\section{Geolocation}
Geolocation refers to the process of finding the absolute position of a target, often in terms of a coordinate system like latitude/longitude/elevation. This information is often more useful than only knowing the direction which an emitter lies in. However, it is shown that by having multiple DF stations, the process of triangulation may be used to geolocate a device from direction bearings \cite{poisel2012electronic}. 

This process is shown graphically in \autoref{fig:lit-triangulation-from-df}, where multiple DF stations ($S_{1}$ through to $S_{M}$) are used to locate the x,y,z coordinates of the target $x_{T}$. Note that this geolocation process in the figure is for airborne DF systems searching for a ground based target. However, the system could easily be simplified to a purely terrestrial process.

The relevance of this note about geolocation to this work is that it is not necessary to attempt to design a system which can do geolocation natively. Rather, a DF system can be design which can later be duplicated in order to provide geolocation capabilities. 

\begin{figure}[p] 
  \centering
  \includegraphics[width=0.6\textwidth]{./img/lit_review/triangulation_from_df.pdf}
  \caption{Using triangulation from multiple DF stations to ascertain the geographic location of a target. Source: \cite{poisel2012electronic}}
  \label{fig:lit-triangulation-from-df}
\end{figure}

\section{Overview of Direction Finding}
In this section, an analysis is made of different the direction finding techniques which exist. The most applicable of these will be examined in more details following.
Classical methods of direction finding algorithms \cite{tuncer2009classical}.
\begin{itemize}
	\item Beamforming: by introducing the correct phase delay to each channel of the array, the array factor can be made to be such that the signal in quesetion is added coherently by each element of the array.
		This phase delay indicates the direction of arrival of the signal. The coherent addition of the signals allows for much higher SNR. 
\end{itemize}

\section{Radiometer}
A radiometer is a device which is able to provide a very high accuracy approximation of noise power by averaging a large number of noise samples over a long time period. Due to the high accuracy measurements it can make, it is able to detect small changes in received power. 
It does this by achieving a high sensitivity. Sensitivity is the measure of how weak a signal and instrument is able to detect.

We will define power in terms of a matched load heated to a certain temperature observed over a certain bandwidth.
\begin{equation}
  P = kTB
\end{equation}
where \(k \approxeq \SI{1.38e-23}{\joule\per\kelvin}\), the Boltzmann constant. 

System temperature is a combination of noise powers from atmospheric emissions, the warm earth, the cosmic microwave background, receiver noise figure, losses in the RF chain and others. These noise sources mask the RFI signal which we are trying to locate. While typically an RFI signal below the noise floor would not be an issue, in the case of a radio astronomy reserver that signal will in all likelihood still be a problem because the noise floor of the MeerKAT array is so much lower than the RFI DF instrument. In essence, a signal which will be very loud to the telescope may be difficult for the DF system to even detect. Effort will hence need to go into ensuring that this instrument being designed will be able to see signals below its own noise floor. 

As the noise at an antenna is a combination of a multitude of noise sources, the central limit theorem states that output of the antenna will be approximately a normal (Gaussian) distribution. 

The noise temperature is defined as the noise power per unit bandwidth over the Boltzmann constant:
\begin{equation}
  T_N = \frac{P_v}{k}
\end{equation}

Assuming the power of a noise source remains constant, a single sample of the noise source has an RMS error of approximately \(\sqrt{2}T_{sys}\). However, by integrating the noise power from a certain bandwidth \(\Delta B\) over some integration time \(\tau\) the error can be significantly reduced to
\begin{equation}
  \sigma_{T} = \frac{\sqrt{2}T_{sys}}{\sqrt{2B\tau}} = \frac{T_{sys}}{\sqrt{B \tau}}
\end{equation}
Where \(\sigma_{T}\) is the RMS error in the measurement of the noise temperature, \(T\), and \(T_{sys}\) is the actual system noise temperature. Note that \(2B\tau\) is the number of samples acquired

This process used in a radiometer of acertaining a high accuracy approximation of a received signal by integrating the signal over some observation period can also be used in the context of a direction finding system. For this application, a long observation period may be used to extract a weak signal which is burried in noise so that the weak signal may be processed.

\begin{equation}
  \frac{S}{N} = \frac{S}{N}\sqrt{B\tau}
\end{equation}

Tsys = Tsky + Trx where Tsky is thestuff above and Trx is Johnson noise from electronic components. Tsky can't do anything about. Trx lowered by cooling components. 
The Trx is as a result of the Johnson-Nyquist noise. 

Extension to interferometry:

\(SEFD / (N(N-1))/2 \tau 2B)\)

Sources: \url{https://casper.berkeley.edu/astrobaki/index.php/Radiometer_Equation}
\url{https://casper.berkeley.edu/astrobaki/index.php/Radiometer_Equation_Applied_to_Telescopes}
\url{https://www.cv.nrao.edu/course/astr534/Radiometers.html}


